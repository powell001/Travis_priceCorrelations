{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takes in xlsx file with tabs, calculates correlation moving averages for 20 years, does some groupby visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'helperFunctions.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xlrd #needed for getting xlsx sheet names\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image\n",
    "####################################################################\n",
    "%run helperFunctions.ipynb #loads defs from other file,cleaner code \n",
    "####################################################################\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromXLSXtoDF(sheetNames_param, xlsxData_param):\n",
    "    allDF = []\n",
    "    for i in sheetNames_param:\n",
    "        # print the sheet name (not necessary) but print statements give valuable feedback to the programmer and are used everywhere \n",
    "        # in the development process.\n",
    "        print(\"Reading in sheet:\", i)\n",
    "        # so read each sheet named \"i\", and grab only columns 0 and 5 (which contain the relevant data)\n",
    "        df = pd.read_excel(xlsxData_param, sheet_name=i, usecols=[0, 5])\n",
    "        # set the timestamp to the index, this makes time series analysis easier.\n",
    "        df = df.set_index(\"Date\")\n",
    "        # calculate diff and percent change, should be done per year\n",
    "        # diff is the first difference, so the change in data from one day to the next.  \n",
    "        df[\"PremiumDiff\"] = df[\"Premium\"].diff(1)\n",
    "        # percent change is the change from one day to the next.\n",
    "        df[\"PremiumPrctChange\"] = df[\"Premium\"].pct_change(1)\n",
    "        # add the dataframe to the list of dataframes\n",
    "        allDF.append(df)\n",
    "    # concatenate across column (axis=0), use the index as key)\n",
    "    result = pd.concat(allDF, axis=0, join='outer')\n",
    "    # change names of columns to the sheetnames\n",
    "    # result.columns = sheetNames\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small function to get names of sheets,  If all the names in the sheets are used, then you could do something like: sheetNames = getSheetNames.  If not all names are used, you can remove those names that are not used by hand or programatically: keepThese = [x for x in sheetNames if x not in dontKeep], so dontKeep looks something like: dontKeep = [sheetIDontWant1, sheetIDontWant2, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSheetNames(xlsxData_param):\n",
    "    xls = xlrd.open_workbook(xlsxData_param, on_demand=True)\n",
    "    return(xls.sheet_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes the required names of the Excel sheets and the Excel file and runs the function fromXLSXtoDF defined in the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getSheetNames('../data/Pna Prem vs Brl - Jeff.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeff001/Travis_priceCorrelations/code/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pna Feb17', 'Pna Mar17', 'Pna Apr17', 'Pna May17', 'Pna Jun17', 'Pna Jul17', 'Pna Aug17', 'Pna Feb18', 'Pna Mar18', 'Pna Apr18', 'Pna May18', 'Pna Jun18', 'Pna Jul18', 'Pna Aug18', 'Pna Sep18', 'Pna Oct18', 'Pna Nov18', 'Pna Dec18', 'Pna Feb19', 'Pna Mar19', 'Pna Apr19', 'Pna May19', 'Pna Jun19', 'Pna Jul19', 'Pna Aug19', 'Pna Sep19', 'Pna Oct19', 'Pna Nov19', 'Pna Dec19', 'Pna Feb20', 'Pna Mar20', 'Pna Apr20', 'Pna May20', 'Pna Jun20', 'Pna Jul20', 'Pna Aug20', 'Pna Sep20', 'Pna Oct20', 'Pna Feb21', 'Pna Mar21', 'Pna Apr21', 'Pna May21', 'Pna Jun21', 'Pna Jul21']\n"
     ]
    }
   ],
   "source": [
    "print(getSheetNames('../../data/raw/Pna_Prem_Upload_Sheet_no_empty_rows.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetNames = ['SB Par Mar17', 'SB Par Mar18', 'SB Par Mar19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate correlations for raw data\n",
    "\n",
    "#Read in the name of the Excel file\n",
    "xlsxData = '../data/Pna Prem vs Brl - Jeff.xlsx'\n",
    "\n",
    "#Run the function\n",
    "sbYears = fromXLSXtoDF(sheetNames, xlsxData)\n",
    "\n",
    "#Drop missing values\n",
    "sbYears = sbYears.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads the Brazilian currency data.  We didn't write a function because we only do these steps once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in BRL dta\n",
    "\n",
    "#Read in data from the same Excel file in sheet named 'Brl'\n",
    "brl = pd.read_excel('../data/Pna Prem vs Brl - Jeff.xlsx', 'Brl')\n",
    "\n",
    "#Set Date (GMT) as the index, which makes times series analysis easier\n",
    "brl = brl.set_index('Date (GMT)')\n",
    "\n",
    "#Re-naming index to Date in order to merge \n",
    "brl.index.name = 'Date' \n",
    "\n",
    "#Calculate the percentage change, just like in the function \n",
    "brl['BrlPrctChange'] = brl[\"Last\"].pct_change(1)\n",
    "\n",
    "#Calculate the first differeence, just like in the function\n",
    "brl['BrlDiff'] = brl[\"Last\"].diff(1)\n",
    "\n",
    "#Take only the relevant columns of the Pandas dataframe\n",
    "brl = brl[[\"Last\", \"BrlDiff\", \"BrlPrctChange\"]]\n",
    "\n",
    "#Rename the columns called Last to Brl\n",
    "brl = brl.rename(columns = {'Last':'Brl'})\n",
    "\n",
    "#Drop missing values\n",
    "brl = brl.dropna()\n",
    "\n",
    "#Show me the results\n",
    "brl.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two data frames created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "merD = pd.merge(sbYears,brl,how='inner',on='Date')\n",
    "merD.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is not continuous over the years, so only take those days for which data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = merD\n",
    "year2016 = df1['2016-06-07': '2017-03-15']\n",
    "print(\"2016:\", year2016.shape)  #print states to find out how much data each dataframe holds\n",
    "year2017 = df1['2017-06-05': '2018-03-15']\n",
    "print(\"2017:\", year2017.shape)\n",
    "year2018 = df1['2018-06-05': '2019-03-15']\n",
    "print(\"2018:\", year2018.shape)\n",
    "year2019 = df1['2019-06-05': '2020-03-15']\n",
    "print(\"2019:\", year2019.shape)  #2019 is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data.  The difference in scale of the data distorts any visual representation in the realationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2017[['PremiumPrctChange', 'BrlPrctChange']].plot(figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrWindow(prem_param, brl_param, mvWindows):\n",
    "    corrMv = []\n",
    "    for i in range(0,prem1.size - mvWindows):\n",
    "        cor1 = prem_param[i:i+mvWindows].corr(brl_param[i:i+mvWindows])\n",
    "        corrMv.append(cor1)\n",
    "\n",
    "    #reindex using subset of the dates\n",
    "    df = pd.DataFrame({'moving_Corr': corrMv},\n",
    "                  index = prem1.index[0:prem1.size - mvWindows])    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code above on the premium and Brazil data.\n",
    "\n",
    "prem1 = df1[\"PremiumPrctChange\"]['2018-06-05': '2019-03-15']\n",
    "brl1  = df1[\"BrlPrctChange\"]['2018-06-05': '2019-03-15']\n",
    "moveWindows = 20    \n",
    "df = corrWindow(prem1, brl1, moveWindows)    \n",
    "df.plot(figsize=(15,7))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prem1 = df1[\"Premium\"]['2018-06-05': '2019-03-15']\n",
    "brl1  = df1[\"Brl\"]['2018-06-05': '2019-03-15']\n",
    "moveWindows = 20    \n",
    "df = corrWindow(prem1, brl1, moveWindows)    \n",
    "df.plot(figsize=(15,7))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resample method is super handy, the \"m\" stands for monthly (there is a \"w\").  So, resample the data per month and take the monthly median (or mean or whatever).\n",
    "\n",
    "merD[[\"PremiumPrctChange\", \"BrlPrctChange\"]].resample(\"m\").median().plot(figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaleDF is imported from helperFunctions\n",
    "sDf = scaleDF(merD)\n",
    "sDf[[\"PremiumPrctChange\", \"BrlPrctChange\"]].resample(\"m\").median().plot(figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the months for which we have data.\n",
    "syear2016 = sDf['2016-06-05': '2017-03-15']\n",
    "syear2017 = sDf['2017-06-05': '2018-03-15']\n",
    "syear2018 = sDf['2018-06-05': '2019-03-15']\n",
    "syear2019 = sDf['2019-06-05': '2020-03-15']\n",
    "\n",
    "# Let's plot SPX and VIX cumulative returns with recession overlay\n",
    "plot_cols = ['Premium', 'Brl']\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,7), sharex=True, sharey=False)\n",
    "syear2016[plot_cols].plot(subplots=True, ax=axes)\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,7), sharex=True, sharey=False)\n",
    "syear2017[plot_cols].plot(subplots=True, ax=axes)\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,7), sharex=True, sharey=False)\n",
    "syear2018[plot_cols].plot(subplots=True, ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot SPX and VIX cumulative returns with recession overlay\n",
    "plot_cols = ['Premium']\n",
    "fig, axes = plt.subplots(1,1, figsize=(15,3), sharex=True, sharey=True)\n",
    "syear2016[plot_cols].plot(subplots=True, ax=axes)\n",
    "fig, axes = plt.subplots(1,1, figsize=(15,3), sharex=True, sharey=True)\n",
    "syear2017[plot_cols].plot(subplots=True, ax=axes)\n",
    "fig, axes = plt.subplots(1,1, figsize=(15,3), sharex=True, sharey=True)\n",
    "syear2018[plot_cols].plot(subplots=True, ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to try, merge by month, day doesn't work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

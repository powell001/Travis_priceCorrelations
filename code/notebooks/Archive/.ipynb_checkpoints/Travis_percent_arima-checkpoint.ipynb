{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1080 with 0 Axes>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "plt.figure(figsize=(12, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Data\n",
    "\n",
    "def fromXLSXtoDF(sheetNames_param, xlsxData_param):\n",
    "    allDF = []\n",
    "    for i in sheetNames_param:\n",
    "        # print the sheet name (not necessary)\n",
    "        print(i)\n",
    "        # so read each sheet named \"i\", and just the first two columns 0 and 1\n",
    "        df = pd.read_excel(xlsxData_param, sheet_name=i, usecols=[0, 1])\n",
    "        # set the timestamp to the index\n",
    "        df = df.set_index(\"Timestamp\")\n",
    "        # add the dataframe to the list of dataframes\n",
    "        allDF.append(df)\n",
    "    # concatenate across rows (axis=1), use the index as key)\n",
    "    result = pd.concat(allDF, axis=1, join='outer')\n",
    "    # change names of columns to the sheetnames\n",
    "    result.columns = sheetNames\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function creat Travis files\n",
    "\n",
    "def percentComm(data1, commodName_param, percent_param, change_param, conversions):\n",
    "    percentChange = pd.DataFrame()\n",
    "    allDFsPerc = []\n",
    "    for i in percent_param:\n",
    "        data2 = data1.iloc[::-1].pct_change(i)\n",
    "        allDFsPerc.append(data2[::-1])\n",
    "        \n",
    "    percentChange = pd.concat(allDFsPerc, axis=1, join='inner')\n",
    "    percentChange.columns = ['% Move', 'W%mv', 'Mth%mv']\n",
    "    \n",
    "    allDFsChange = []\n",
    "    for i in change_param:\n",
    "        data2 = data1.iloc[::-1].diff(i)\n",
    "        allDFsChange.append(data2[::-1])\n",
    "        \n",
    "    change = pd.concat(allDFsChange, axis=1, join='inner')\n",
    "    change.columns = ['Wmv', 'Mthmv']    \n",
    "   \n",
    "    travisDF = pd.concat([data1, percentChange, change], axis=1, join=\"inner\")\n",
    "    \n",
    "    #conversions\n",
    "    firstDiff = data1.iloc[::-1].diff(1)\n",
    "    travisDF[\"DMTmv\"] = (conversions.get(commodName_param) * firstDiff)/100\n",
    "     \n",
    "    #order the columns\n",
    "    travisDF = travisDF[[commodName_param, '% Move', 'Wmv', 'W%mv', 'Mthmv', 'Mth%mv', 'DMTmv']] \n",
    "   \n",
    "    #save it\n",
    "    travisDF.to_csv('travisDF_' + commodName_param + '.csv', index = True)\n",
    "    travisDF.head(5)\n",
    "    \n",
    "    return(travisDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to standardize data, needed to mitigate small values\n",
    "\n",
    "def scaleDF(myDF):\n",
    "    resultsStd = myDF.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    results_scaled = min_max_scaler.fit_transform(resultsStd)\n",
    "    myresults_scaled = pd.DataFrame(results_scaled)\n",
    "    \n",
    "    # change names of columns to the sheetnames\n",
    "    myresults_scaled.columns = myDF.columns\n",
    "    \n",
    "    # add index back in\n",
    "    indx = myDF.index\n",
    "    myresults_scaled.set_index(indx, inplace=True)\n",
    "    print(myresults_scaled.head())\n",
    "    return(myresults_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a769931bc5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaleDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "scaleDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which commodities\n",
    "sheetNames = [\"Soybean\", \"Soymeal\", \"Soyoil\", \"Corn\", \"DalianSBM\", \"DalianSBO\", \"BRL\", \"CNY\"]\n",
    "sheetNames = [\"Soybean\", \"Soymeal\"]\n",
    "\n",
    "#select data from .xlsx sheet\n",
    "xlsxData = \"../../data/raw/Price Correlation.xlsx\"\n",
    "df = fromXLSXtoDF(sheetNames, xlsxData)\n",
    "df.head(5)\n",
    "\n",
    "#create Travis data\n",
    "percentDiffs = [1,4,22]\n",
    "diffs = [4,22]\n",
    "conversions = {\"Soybean\":36.7454, \"Soymeal\":1, \"Soyoil\":1, \"Corn\":1, \"DalianSBM\":1, \"DalianSBO\":1, \"BRL\":1, \"CNY\":1}\n",
    "\n",
    "percentAllComm = []\n",
    "for i in sheetNames:   \n",
    "    commod1 = df[[i]]\n",
    "    #print(commod1)\n",
    "    data3 = percentComm(commod1, i, percentDiffs, diffs, conversions)\n",
    "    percentAllComm.append(data3)\n",
    "    \n",
    "#print(percentAllComm[0])      \n",
    "#print(percentAllComm[1])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations\n",
    "sheetNames = [\"Soybean\", \"Soymeal\", \"Soyoil\", \"Corn\", \"DalianSBM\", \"DalianSBO\", \"BRL\", \"CNY\"]\n",
    "\n",
    "#select data from .xlsx sheet\n",
    "xlsxData = \"../../data/raw/Price Correlation.xlsx\"\n",
    "df = fromXLSXtoDF(sheetNames, xlsxData)\n",
    "\n",
    "# plot with ugly colors\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "df.plot(figsize=(20,8));\n",
    "plt.figure(figsize=(12, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_scaled = scaleDF(df)\n",
    "fig = plt.figure()\n",
    "res_scaled.plot(figsize=(20,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(df.Soybean)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
